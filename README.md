
<!-- Inline CSS styles -->
<style>
  /* Big headings in primary blue */
  h1, h2 {
    color: #2a6496;
  }
  
  /* Normal text in dark color */
  p, li, summary {
    color: #333;
  }
  
  /* Add spacing between list items */
  li {
    margin-bottom: 8px;
  }
  
  /* Ensure images are responsive */
  img {
    max-width: 100%;
    height: auto;
    display: block;
    margin: 1rem auto;
  }
  
  /* Dropdown pointer cursor */
  summary {
    cursor: pointer;
    font-weight: bold;
  }
  
  /* Center content */
  .center {
    text-align: center;
  }
  
  /* System diagram */
  .system-img {
    max-width: 100%;
    box-shadow: 0 4px 8px rgba(0,0,0,0.1);
    border-radius: 8px;
  }
  
  /* Team table styling */
  table {
    width: 100%;
    margin: 2rem auto;
  }
  
  td {
    padding: 1rem;
    text-align: center;
    vertical-align: top;
  }
  
  /* Team logo consistent sizing */
  .team-logo {
    height: 80px;
    width: auto;
    max-width: 150px;
    object-fit: contain;
    margin-bottom: 1rem;
  }
  
  /* Team member photo consistent sizing */
  .team-photo {
    height: 80px;
    width: 80px;
    border-radius: 50%;
    object-fit: cover;
    margin: 0.5rem auto;
    display: block;
  }
  
  /* Institution name consistent height */
  .institution-name {
    min-height: 3rem;
    display: flex;
    flex-direction: column;
    justify-content: center;
    margin-bottom: 1rem;
  }
</style>

<p style="font-size: 1.2em; color: #666; text-align: center; font-style: italic;">
Digitale Soforthilfe bei problematischen Inhalten, F√∂rderung der Selbstwirksamkeit von jungen Nutzer:innen, und institutionelle Vernetzung f√ºr eine sichere Online-Schweiz
</p>

---

## üìã Projekt-√úberblick

### Das Problem: Online-Gefahren f√ºr Junge Nutzer:innen
Kinder und Jugendliche stossen immer h√§ufiger auf problematische Inhalte wie hate speech, Falschinformationen oder extreme Inhalte in sozialen Medien. Bestehende Schutzmassnahmen zielen oft auf Pr√§vention ab - jedoch fehlt es an direkter Unterst√ºtzung f√ºr Kinder und Lehrpersonen nach akuter Konfrontation mit solchen Inhalten.

### Unsere L√∂sungsansatz: Flag&Safe
Wir entwickeln mit "Flag&Safe" eine kindgerechte Plattform, auf der junge Nutzer:innen bedenkliche Online-Inhalte einfach und sicher melden k√∂nnen. Die Plattform f√ºhrt eine automatische Vorpr√ºfung durch und leitet dringende F√§lle an ein Netzwerk von Fachpersonen (z.B. Schulpsycholog:innen, Beratungsstellen) weiter. Dabei bleiben Daten und Metadaten der Inhalte erhalten, was diese Fachpersonen bef√§higt, schnell und unkompliziert einzugreifen.

<details>
<summary><strong>Mehr zur Vision</strong></summary>

In j√ºngster Zeit h√§ufen sich Berichte √ºber radikalisierende Inhalte in sozialen Medien ‚Äì auch in der Schweiz sorgen Schlagzeilen wie ‚ÄûRadikalisierung im Internet: Mit TikTok zum IS-Fanatiker" f√ºr Aufmerksamkeit. Gleichzeitig berichten immer mehr junge Nutzer:innen, dass sie in ihren Social-Media-Feeds auf unerw√ºnschte sexuelle, irref√ºhrende und hasserf√ºllte Inhalte stossen.

Mit dem Inkrafttreten des Digital Services Act in der Europ√§ischen Union werden strengere Regeln f√ºr soziale Medien eingef√ºhrt, insbesondere um Kinder besser zu sch√ºtzen. Ein zentraler Aspekt solcher Massnahmen sind sogenannte "Trusted Flagger". Diese Akteure identifizieren problematische Inhalte, melden sie und entfernen sie von Social-Media Plattformen. Jedoch existiert in der Schweiz keine entsprechende Meldestelle. Dieses Problem versuchen wir, mit dem Flag&Safe Projekt zu l√∂sen.

</details>

---

## üîÑ So funktioniert Flag&Safe

<img src="data/TrustedFlagger.png" alt="Systemdiagramm der Flag&Safe Plattform" class="system-img">

<details>
<summary><strong>Schritt A: Kinder und Jugendliche melden Inhalte</strong></summary>

Wenn Kinder oder Jugendliche in sozialen Medien auf problematische Inhalte stossen (z.B. extreme, radikale, hasserf√ºllte oder sexuelle Inhalte), k√∂nnen sie diese √ºber die Flag&Safe Plattform melden. Hierf√ºr schicken sie einen link zum Inhalt oder nutzen einen integrierten Chatbot.

</details>

<details>
<summary><strong>Schritt B: Inhalte werden gesammelt und gepr√ºft</strong></summary>

Sobald ein potenziell problematischer Inhalt gemeldet wird, sammelt unser System diesen automatisch und speichert ihn sicher ab. Spezielle Computerprogramme schauen sich den Inhalt unter Zuhilfenahme von k√ºnstlicher Intelligenz an und pr√ºfen, ob er gegen Regeln verst√∂√üt oder sogar illegal sein k√∂nnte. Dabei werden auch bekannte Listen mit verbotenen Inhalten abgeglichen.

</details>

<details>
<summary><strong>Schritt C: Automatische Meldung an Plattformen und Beh√∂rden</strong></summary>

Wenn ein Inhalt gegen die Regeln der sozialen Medien oder gegen Gesetze verst√∂√üt, meldet unser System ihn automatisch direkt an die Betreiber der Social-Media-Plattform (z.B. TikTok, Instagram). Wenn der Inhalt klar illegal ist, k√∂nnte der Inhalt sogar vollautomatisch an die zust√§ndigen Polizeibeh√∂rden gemeldet werden.

</details>

<details>
<summary><strong>Schritt D: Schnelle Hilfe f√ºr Betroffene</strong></summary>

Gleichzeitig informiert das System auch lokale Hilfsstellen, wie Schulpsychologen oder Medienp√§dagogen. Diese Fachleute erhalten dann die wichtigsten Informationen √ºber den gemeldeten Inhalt und k√∂nnen dem betroffenen Kind schnell helfen, zum Beispiel durch ein Beratungsgespr√§ch.

</details>

<details>
<summary><strong>Schritt E: System lernt dazu und wird besser</strong></summary>

Alle gemeldeten Inhalte werden gesammelt und helfen dabei, unser System immer weiter zu verbessern. Die k√ºnstliche Intelligenz lernt aus neuen F√§llen unter Wahrung der Anonymit√§t der beteiligten Personen und kann so problematische Inhalte in Zukunft noch schneller und genauer erkennen. Wir k√∂nnen ausserdem so auch besser verstehen, welche potenziell gef√§hrlichen Trends sich gerade online entwickeln.

</details>

<details>
<summary><strong>Schritt F: Infos f√ºr die Politik</strong></summary>

Unsere gesammelten Erkenntnisse geben wir auch an die Politik weiter. So k√∂nnen Politikerinnen und Politiker besser verstehen, welchen Gefahren Kinder und Jugendliche online ausgesetzt sind und neue Gesetze entwickeln, um sie besser zu sch√ºtzen.

</details>

---

## üéØ Was wir bieten

### Unsere Outputs
- ‚úÖ **Trusted Flagger Plattform:** Eine Open-Source Softwarel√∂sung, mit der Kinder und Jugendliche problematische Inhalte einfach melden k√∂nnen.
- ‚úÖ **Workshops:** Workshops f√ºr Schulen und Beratungsstellen, um Bed√ºrfnisse zu verstehen und den Umgang mit der Plattform zu schulen.
- ‚úÖ **Usability-Studie:** Tests mit Kindern und Jugendlichen zur Evaluierung und Verbesserung der Plattform.
- ‚úÖ **Wissenschaftliche Ver√∂ffentlichungen:** Publikationen zu technischen Entwicklungen und Ergebnissen.

### Zielgruppen
Unser Angebot richtet sich speziell an **Kinder und Jugendliche in der Schweiz**, die auf Social-Media-Plattformen aktiv sind.

---

## üë• Das Projektteam

Ein interdisziplin√§res Team aus Informatik, Rechtswissenschaft und Medienp√§dagogik:

<table>
  <tr>
    <td>
      <img src="data/HSG_Logo_EN_RGB.svg.png" alt="HSG Logo" class="team-logo"><br>
      <div class="institution-name">
        <strong>Universit√§t St.Gallen</strong><br>
        Institut f√ºr Informatik
      </div>
      <img src="data/Luka.jpg" alt="Luka Bekavac" class="team-photo">
      <strong>Doktorand Luka Bekavac</strong><br><br>
      <img src="https://storage.inrupt.com/f531f8ef-cd9d-474a-9fa6-70026b37c847/public/publicPortrait-square.jpg" alt="Simon Mayer" class="team-photo">
      <strong>Prof. Simon Mayer</strong>
    </td>
    <td>
      <img src="data/Logo_Universit√©_de_Lausanne.png" alt="Lausanne Logo" class="team-logo"><br>
      <div class="institution-name">
        <strong>Universit√§t Lausanne</strong><br>
        Rechtswissenschaftliche Abteilung
      </div>
      <img src="data/Alice.jpeg" alt="Alice Palmieri" class="team-photo">
      <strong>Doktorand Alice Palmieri</strong><br><br>
      <img src="data/aurelia.jpg" alt="Aurelia Tam√≤-Larrieux" class="team-photo">
      <strong>Prof. Aurelia Tam√≤-Larrieux</strong>
    </td>
    <td>
      <img src="data/logo_stadt_st.gallen.jpg" alt="St.Gallen Logo" class="team-logo"><br>
      <div class="institution-name">
        <strong>Primarschule Halden</strong><br>
        St.Gallen
      </div>
      <img src="data/Benjamin-Lizinger.jpg" alt="Benjamin Lizinger" class="team-photo">
      <strong>Benjamin Lizinger</strong><br>
      Medienp√§dagoge
    </td>
    <td>
      <img src="data/Maastricht_University_logo.svg.png" alt="Maastricht Logo" class="team-logo"><br>
      <div class="institution-name">
        <strong>Universit√§t Maastricht</strong><br>
        Law&Tech Lab
      </div>
      <img src="data/Konrad.jpeg" alt="Konrad Kollnig" class="team-photo">
      <strong>Prof. Konrad Kollnig</strong><br>
      (Unterst√ºtzende Funktion)
    </td>
  </tr>
</table>

---

## üìÖ Zeitplan

**Projektstart:** 01.04.2025  
**Projektende:** 30.04.2026

### Nachhaltigkeit
Die Universit√§t St.Gallen sichert den Betrieb der Plattform f√ºr 5 Jahre nach Projektende zu. Die Open-Source-L√∂sung erm√∂glicht zudem die Weiterentwicklung und den Betrieb der Plattform durch Dritte.

---

## üìÑ Lizenz

Dieses Projekt wird als Open-Source-L√∂sung entwickelt und bereitgestellt.

---

<div class="center">

<strong>¬© 2025 Flag&Safe Projekt</strong>

<p style="font-style: italic;">Ein Projekt mit Unterst√ºtzung der</p>

<img src="data/Palatin.png" alt="Palatin Stiftung" style="max-width: 200px; height: auto;">

</div>
